{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e1a6b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Attendance data from https://edoofa-ums-90164.bubbleapps.io/version-test/api/1.1/obj... Cursor: 0\n",
      "Fetched 16 new records, Total fetched: 16\n",
      "Exiting loop, fetched less than 100 records.\n",
      "Fetched 16 records for Attendance.\n",
      "Fetching Attendance-Summary data from https://edoofa-ums-90164.bubbleapps.io/version-test/api/1.1/obj... Cursor: 0\n",
      "Fetched 12 new records, Total fetched: 12\n",
      "Exiting loop, fetched less than 100 records.\n",
      "Fetched 12 records for Attendance-Summary.\n",
      "Fetching Student data from https://edoofa-portal.bubbleapps.io/api/1.1/obj... Cursor: 0\n",
      "Fetched 1 new records, Total fetched: 1\n",
      "Exiting loop, fetched less than 100 records.\n",
      "Fetched 1 records for Student.\n",
      "Fetching Engagement data from https://edoofa-portal.bubbleapps.io/api/1.1/obj... Cursor: 0\n",
      "Fetched 22 new records, Total fetched: 22\n",
      "Exiting loop, fetched less than 100 records.\n",
      "Fetched 22 records for Engagement.\n",
      "adding new records\n",
      "No data to post for student ID Precious EWYL22E0313\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001EB78E4DBD0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mauriceyeng\\AppData\\Local\\Temp\\ipykernel_11676\\1563033858.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  engagement_df.loc[:, 'ewyl'] = engagement_df['student'].map(student_id_to_EWYL)\n",
      "C:\\Users\\mauriceyeng\\AppData\\Local\\Temp\\ipykernel_11676\\1563033858.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  engagement_df.loc[:, 'ewyl'] = engagement_df['student'].map(student_id_to_EWYL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created a new row in Attendance-Summary.\n",
      "posted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mauriceyeng\\AppData\\Local\\Temp\\ipykernel_11676\\1563033858.py:211: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created a new row in Attendance-Summary.\n",
      "posted\n",
      "Successfully created a new row in Attendance-Summary.\n",
      "posted\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime  # Change the import statement\n",
    "from datetime import timedelta\n",
    "\n",
    "# Define global variables for dataframes\n",
    "student_df = None\n",
    "engagement_df = None\n",
    "ums_att_df = None\n",
    "ums_avg_att_df = None\n",
    "ums_upload_avg_att=None\n",
    "\n",
    "# Edoofy app information\n",
    "edoofy_base_url = \"https://edoofa-portal.bubbleapps.io/api/1.1/obj\"\n",
    "edoofy_bearer_token = \"2cde31d8f48919a2db1467cc06a56132\"\n",
    "edoofy_headers = {'Authorization': f'Bearer {edoofy_bearer_token}'}\n",
    "\n",
    "# UMS app information\n",
    "ums_base_url = \"https://edoofa-ums-90164.bubbleapps.io/version-test/api/1.1/obj\"\n",
    "ums_bearer_token = \"786720e8eb68de7054d1149b56cc04f9\"\n",
    "ums_headers = {'Authorization': f'Bearer {ums_bearer_token}'}\n",
    "\n",
    "# Asynchronous function to fetch data from a table\n",
    "async def fetch_table_data(session, base_url, headers, table, constraints=None):\n",
    "    records = []\n",
    "    cursor = 0\n",
    "    total_fetched = 0\n",
    "\n",
    "    while True:\n",
    "        params = {'limit': 100, 'cursor': cursor}\n",
    "        if constraints:\n",
    "            params['constraints'] = json.dumps(constraints)\n",
    "\n",
    "        api_url = f\"{base_url}/{table}\"\n",
    "        print(f\"Fetching {table} data from {base_url}... Cursor: {cursor}\")\n",
    "\n",
    "        async with session.get(api_url, headers=headers, params=params) as response:\n",
    "            if response.status != 200:\n",
    "                print(f\"Failed to fetch data from {table}: {await response.text()}\")\n",
    "                break\n",
    "\n",
    "            data = await response.json()\n",
    "            new_records = data['response']['results']\n",
    "            records.extend(new_records)\n",
    "            total_fetched += len(new_records)\n",
    "\n",
    "            print(f\"Fetched {len(new_records)} new records, Total fetched: {total_fetched}\")\n",
    "\n",
    "            cursor += 100\n",
    "\n",
    "            if len(new_records) < 100:\n",
    "                print(f\"Exiting loop, fetched less than 100 records.\")\n",
    "                break\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    print(f\"Fetched {len(df)} records for {table}.\")\n",
    "    return df\n",
    "\n",
    "def map_students_to_engagement(student_df, engagement_df):\n",
    "    # Ensure '_id' and 'EWYL-group-name' are in student_df\n",
    "    if '_id' in student_df.columns and 'EWYL-group-name' in student_df.columns:\n",
    "        student_id_to_EWYL = dict(zip(student_df['_id'], student_df['EWYL-group-name']))\n",
    "        engagement_df.loc[:, 'ewyl'] = engagement_df['student'].map(student_id_to_EWYL)\n",
    "    else:\n",
    "        print(\"Error: '_id' or 'EWYL-group-name' not in student_df columns\")\n",
    "    return engagement_df\n",
    "\n",
    "\n",
    "\n",
    "def process_engagement_data(ums_att_df, engagement_df, student_df, student_id):\n",
    "    # Create mappings\n",
    "    student_to_kam_mapping = dict(zip(student_df['_id'], student_df['KAM-group-name']))\n",
    "    student_to_ewyl_mapping = dict(zip(student_df['_id'], student_df['EWYL-group-name']))\n",
    "\n",
    "    # Add KAM-group-name and ewyl columns to the engagement dataframe\n",
    "    engagement_df['KAM-group-name'] = engagement_df['student'].map(student_to_kam_mapping)\n",
    "    engagement_df['ewyl'] = engagement_df['student'].map(student_to_ewyl_mapping)\n",
    "\n",
    "    # Find the latest date for the specific student in ums_att_df\n",
    "    student_latest_ums_date = pd.to_datetime(ums_att_df[ums_att_df['ewyl-group-name'] == student_id]['date'].max())\n",
    "\n",
    "    if pd.isnull(student_latest_ums_date):\n",
    "        # Process all records from engagement_df for this student\n",
    "        student_engagement_records = engagement_df[engagement_df['ewyl'] == student_id]\n",
    "        print(\"adding all records\")\n",
    "        \n",
    "    else:\n",
    "        # Process only records newer than the latest in ums_att_df\n",
    "        student_engagement_records = engagement_df[\n",
    "            (engagement_df['student'] == student_id) &\n",
    "            (pd.to_datetime(engagement_df['engagement-date']) > student_latest_ums_date)\n",
    "        ]\n",
    "        print(\"adding new records\")\n",
    "        \n",
    "    return student_engagement_records\n",
    "    \n",
    "\n",
    "# Function to post processed engagement data\n",
    "async def post_processed_data(session, base_url, headers, processed_data):\n",
    "    api_url = f\"{base_url}/Attendance\"\n",
    "    \n",
    "    for index, row in processed_data.iterrows():\n",
    "        data = {\n",
    "            'admissions-group-name': row['KAM-group-name'],\n",
    "            'ewyl-group-name': row['ewyl'],\n",
    "            'attendance-type': row['engagement-type'],\n",
    "            'present': row['daily-attendance'],\n",
    "            'date': row['engagement-date']\n",
    "        }\n",
    "        \n",
    "        async with session.post(api_url, headers=headers, json=data) as response:\n",
    "            if response.status == 201:\n",
    "                print(f\"Successfully posted data for row {index}\")\n",
    "            else:\n",
    "                print(f\"Failed to post data for row {index}: {await response.text()}\")\n",
    "\n",
    "\n",
    "\n",
    "def get_percentage(number_of_present, total_sessions):\n",
    "    if total_sessions == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    percent = (number_of_present / total_sessions) * 100\n",
    "    #print(percent)\n",
    "    return percent\n",
    "\n",
    "# Function to check if a row exists for the current month for a student\n",
    "async def check_if_row_exists(student, year, month, ums_avg_att_df):\n",
    "    # Filtering the ums_avg_att_df to check if there's an existing record for the student\n",
    "    existing_rows = ums_avg_att_df[\n",
    "        (ums_avg_att_df['ewyl-group-name'] == student) &\n",
    "        (ums_avg_att_df['year'] == year) &\n",
    "        (ums_avg_att_df['month'] == month)\n",
    "    ]\n",
    "\n",
    "    if not existing_rows.empty:\n",
    "        # Assuming '_id' is the column name for the row ID\n",
    "        return existing_rows['_id'].iloc[0]\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Function to post a new attendance summary\n",
    "async def post_new_attendance_summary(session, base_url, headers, data):\n",
    "    api_url = f\"{base_url}/Attendance-Summary\"\n",
    "    async with session.post(api_url, headers=headers, json=data) as response:\n",
    "        if response.status == 201:\n",
    "            print(\"Successfully created a new row in Attendance-Summary.\")\n",
    "        else:\n",
    "            print(f\"Failed to create a new row: {await response.text()}\")\n",
    "\n",
    "# Function to patch an existing attendance summary\n",
    "async def patch_attendance_summary(session, base_url, headers, row_id, data):\n",
    "    api_url = f\"{base_url}/Attendance-Summary/{row_id}\"\n",
    "    async with session.patch(api_url, headers=headers, json=data) as response:\n",
    "        if response.status == 200:\n",
    "            print(\"Successfully updated the row in Attendance-Summary.\")\n",
    "        else:\n",
    "            print(f\"Failed to update the row: {await response.text()}\")\n",
    "\n",
    "            \n",
    "\n",
    "async def process_avg_att(session, base_url, headers, combined_df, ums_avg_att_df):\n",
    "    results_df = pd.DataFrame(columns=['student', 'attendance-percentage'])\n",
    "\n",
    "    # Group by 'ewyl-group-name' and 'admissions-group-name'\n",
    "    grouped = combined_df.groupby(['ewyl-group-name', 'admissions-group-name'])\n",
    "    print(grouped)\n",
    "    for (ewyl_group, kam_group_name), group in grouped:\n",
    "        total_sessions = len(group)\n",
    "        number_of_present = group['present'].sum()\n",
    "        attendance_percentage = get_percentage(number_of_present, total_sessions)\n",
    "\n",
    "        # Get the year and month for the latest engagement date\n",
    "        latest_engagement_date = pd.to_datetime(group['date'].max())\n",
    "        current_year = latest_engagement_date.year\n",
    "        current_month = latest_engagement_date.strftime(\"%B\")\n",
    "        first_day_of_month = latest_engagement_date.replace(day=1).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Calculate avg-att-percent-till-last-month\n",
    "        past_records = combined_df[\n",
    "            (combined_df['ewyl-group-name'] == ewyl_group) &\n",
    "            (combined_df['date'] < first_day_of_month)\n",
    "        ]\n",
    "        past_present = past_records['present'].sum()\n",
    "        avg_att_percent_till_last_month = get_percentage(past_present, len(past_records))\n",
    "\n",
    "        row_id = await check_if_row_exists(ewyl_group, current_year, current_month, ums_avg_att_df)\n",
    "\n",
    "        data = {\n",
    "            'ewyl-group-name': ewyl_group,\n",
    "            'admissions-group-name': kam_group_name,\n",
    "            'attendance-percentage': attendance_percentage,\n",
    "            'avg-att-percent-till-last-month': avg_att_percent_till_last_month,\n",
    "            'year': current_year,\n",
    "            'month': current_month,\n",
    "            'first-day-of-month': first_day_of_month\n",
    "        }\n",
    "\n",
    "        if row_id:\n",
    "            await patch_attendance_summary(session, base_url, headers, row_id, data)\n",
    "            print(\"patched\")\n",
    "        else:\n",
    "            await post_new_attendance_summary(session, base_url, headers, data)\n",
    "            print(\"posted\")\n",
    "\n",
    "        new_row = {'student': ewyl_group, 'attendance-percentage': attendance_percentage}\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def main():\n",
    "    global student_df, engagement_this_month_df, engagement_previous_months_df, ums_att_df, ums_avg_att_df\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        # Fetch data from 'ums_att'\n",
    "        ums_att_df = await fetch_table_data(session, ums_base_url, ums_headers, \"Attendance\")\n",
    "        \n",
    "        ums_avg_att_df = await fetch_table_data(session, ums_base_url, ums_headers, \"Attendance-Summary\")\n",
    "        \n",
    "        # Determine the latest date from 'ums_att'\n",
    "        ums_latest = pd.to_datetime(ums_att_df['date'].max())\n",
    "        \n",
    "        # Fetch Student table from Edoofy\n",
    "        student_constraints = [           \n",
    "            {'key': '_id', 'constraint_type': 'equals', 'value': '1695736497533x818400363201798900'}\n",
    "        ]\n",
    "        student_df = await fetch_table_data(session, edoofy_base_url, edoofy_headers, \"Student\", constraints=student_constraints)\n",
    "        \n",
    "        # Fetch engagement data where 'engagement-date' is greater than 'ums_latest'\n",
    "        engagement_constraints = [\n",
    "            #{'key': 'engagement-date', 'constraint_type': 'greater than', 'value': ums_latest.isoformat()},\n",
    "            {'key': 'student', 'constraint_type': 'equals', 'value': '1695736497533x818400363201798900'}\n",
    "        ]\n",
    "        engagement_df = await fetch_table_data(session, edoofy_base_url, edoofy_headers, \"Engagement\", constraints=engagement_constraints)\n",
    "        engagement_df = engagement_df[engagement_df['engagement-type'].isin(['IE Call', 'IE Chat', 'Activity', 'Lesson'])]\n",
    "        \n",
    "        # Calculate the start and end date for the till last month (excluding this month)\n",
    "        latest_engagement_date = pd.to_datetime(engagement_df['engagement-date'].max())\n",
    "        end_date = latest_engagement_date.replace(day=1) - timedelta(days=1)\n",
    "       # start_date = end_date - timedelta(days=365)\n",
    "\n",
    "        # Filter engagement data for the till last month\n",
    "        previous_months_df = engagement_df[            \n",
    "            (pd.to_datetime(engagement_df['engagement-date']) <= end_date)\n",
    "        ]\n",
    "\n",
    "        # Split the data into this month and previous months\n",
    "        this_month_start = latest_engagement_date.replace(day=1)\n",
    "        engagement_this_month_df = engagement_df[\n",
    "            pd.to_datetime(engagement_df['engagement-date']) >= this_month_start\n",
    "        ]\n",
    "        engagement_previous_months_df = previous_months_df\n",
    "        \n",
    "        # Apply mapping to engagement dataframes\n",
    "        engagement_this_month_df = map_students_to_engagement(student_df, engagement_this_month_df)\n",
    "        engagement_previous_months_df = map_students_to_engagement(student_df, engagement_previous_months_df)\n",
    "        \n",
    "        all_processed_data = []\n",
    "\n",
    "        for _, student_row in student_df.iterrows():\n",
    "            student_id = student_row['EWYL-group-name']\n",
    "            processed_df = process_engagement_data(ums_att_df, engagement_df, student_df, student_id)\n",
    "            #print(\"processed-dataframe: \")\n",
    "            #print(processed_df)\n",
    "            # Post processed data for each student\n",
    "            if not processed_df.empty:\n",
    "                await post_processed_data(session, ums_base_url, ums_headers, processed_df)\n",
    "                all_processed_data.append(processed_df)\n",
    "            else:\n",
    "                print(f\"No data to post for student ID {student_id}\")\n",
    "        #print(all_processed_data)\n",
    "        combined_df = pd.concat([ums_att_df] + all_processed_data, ignore_index=True)\n",
    "        #print(combined_df)\n",
    "        # Process average attendance\n",
    "        await process_avg_att(session, ums_base_url, ums_headers, combined_df, ums_avg_att_df)\n",
    "\n",
    "\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59e0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = pd.concat([ums_att_df, new_dataframe], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e799727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b494e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ums_att_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec238425",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(engagement_this_month_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e72ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ums_avg_att_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61db21b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
