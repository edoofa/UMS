{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e425be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import openpyxl  # or import xlsxwriter\n",
    "import logging\n",
    "import json\n",
    "from pandas import Timestamp\n",
    "import calendar\n",
    "from collections import deque\n",
    "\n",
    "# Setup and Configuration\n",
    "EDOOFA_API_ENDPOINT = \"https://edoofa-portal.bubbleapps.io/version-test/api/1.1/obj\"  # Replace with your API endpoint\n",
    "UMS_API_ENDPOINT = \"https://edoofa-ums-90164.bubbleapps.io/version-test/api/1.1/obj\"  # UMS API endpoint\n",
    "EDOOFA_API_TOKEN = \"2cde31d8f48919a2db1467cc06a56132\"  # Edoofa app API token\n",
    "UMS_API_TOKEN = \"8caeed4a8be2be66b70a76bcd486d4bb\"  # UMS app API token\n",
    "\n",
    "def get_headers(endpoint):\n",
    "    if \"edoofa-portal\" in endpoint:\n",
    "        return {\"Authorization\": f\"Bearer {EDOOFA_API_TOKEN}\", \"Content-Type\": \"application/json\"}\n",
    "    elif \"edoofa-ums\" in endpoint:\n",
    "        return {\"Authorization\": f\"Bearer {UMS_API_TOKEN}\", \"Content-Type\": \"application/json\"}\n",
    "    else:\n",
    "        raise ValueError(\"Unknown endpoint\")\n",
    "\n",
    "def fetch_all_attendance_data(start_date, end_date):\n",
    "    all_data = []\n",
    "    cursor = 0\n",
    "    limit = 100\n",
    "    total_records = None\n",
    "    endpoint = f\"{EDOOFA_API_ENDPOINT}/engagement\"\n",
    "    headers = get_headers(endpoint)\n",
    "\n",
    "    while total_records is None or cursor < total_records:\n",
    "        try:\n",
    "            constraints = [\n",
    "                {'key': 'engagement-date', 'constraint_type': 'greater than', 'value': start_date},\n",
    "                {'key': 'engagement-date', 'constraint_type': 'less than', 'value': end_date}\n",
    "            ]\n",
    "            params = {\n",
    "                'constraints': json.dumps(constraints),\n",
    "                'cursor': cursor,\n",
    "                'limit': limit\n",
    "            }\n",
    "            response = requests.get(endpoint, headers=headers, params=params)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            data = response.json()\n",
    "            records = data['response']['results']\n",
    "            all_data.extend(records)\n",
    "            \n",
    "            if total_records is None:\n",
    "                total_records = data['response']['remaining'] + len(records)\n",
    "            cursor += len(records)\n",
    "\n",
    "            logging.info(f\"Fetched {len(records)} records. Total fetched: {cursor}.\")\n",
    "\n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            logging.error(f\"HTTP error occurred: {err}\")\n",
    "            break\n",
    "        except Exception as err:\n",
    "            logging.error(f\"Error occurred: {err}\")\n",
    "            break\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def fetch_student_data():\n",
    "    all_student_data = []\n",
    "    cursor = 0\n",
    "    limit = 100\n",
    "    total_records = None\n",
    "    endpoint = f\"{EDOOFA_API_ENDPOINT}/student\"\n",
    "    headers = get_headers(endpoint)\n",
    "\n",
    "    while total_records is None or cursor < total_records:\n",
    "        try:\n",
    "            params = {'cursor': cursor, 'limit': limit}\n",
    "            response = requests.get(endpoint, headers=headers, params=params)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            data = response.json()\n",
    "            records = data['response']['results']\n",
    "            all_student_data.extend(records)\n",
    "            \n",
    "            if total_records is None:\n",
    "                total_records = data['response']['remaining'] + len(records)\n",
    "            cursor += len(records)\n",
    "\n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            logging.error(f\"HTTP error occurred: {err}\")\n",
    "            break\n",
    "        except Exception as err:\n",
    "            logging.error(f\"Error occurred: {err}\")\n",
    "            break\n",
    "    \n",
    "    if all_student_data: \n",
    "        print(\"Sample student data:\", all_student_data[0])\n",
    "\n",
    "    return all_student_data\n",
    "\n",
    "def map_student_info(student_id, student_data):\n",
    "    for student in student_data:\n",
    "        # Using '_id' as the key to match the student ID\n",
    "        if student['_id'] == student_id:\n",
    "            ewyl_group_name = student.get('EWYL-group-name', 'Unknown')\n",
    "            kam_group_name = student.get('KAM-group-name', 'Unknown')\n",
    "            return ewyl_group_name, kam_group_name\n",
    "    return 'Unknown', 'Unknown'\n",
    "\n",
    "# Data Preprocessing\n",
    "def process_attendance_data(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Data Preprocessing\n",
    "def process_and_export_data(df, student_data):\n",
    "    # Map student ID to EWYL and KAM group names\n",
    "    mapped_values = df['student'].apply(lambda x: map_student_info(x, student_data))\n",
    "    df['ewyl-group-name'], df['admissions-group-name'] = zip(*mapped_values)\n",
    "\n",
    "    # Filter for only 'IE Call' or 'IE Chat' in 'engagement-type'\n",
    "    df = df[df['engagement-type'].isin(['IE Call', 'IE Chat', 'Activity', 'Lesson'])]\n",
    "\n",
    "    # Select specific columns and rename them\n",
    "    columns_to_select = {\n",
    "        'engagement-date': 'date',\n",
    "        'engagement-type': 'attendance-type',\n",
    "        'daily-attendance': 'present',\n",
    "        'ewyl-group-name': 'ewyl-group-name',\n",
    "        'admissions-group-name': 'admissions-group-name'\n",
    "    }\n",
    "    \n",
    "    # Create a new DataFrame with the selected columns\n",
    "    processed_df = df[list(columns_to_select.keys())]\n",
    "    processed_df = processed_df.rename(columns=columns_to_select)\n",
    "\n",
    "    return processed_df\n",
    "\n",
    "def calculate_average_till_last_12_months(grouped_data):\n",
    "    # Initialize the column with 0.0\n",
    "    grouped_data['avg-att-percent-till-last-month'] = 0.0  \n",
    "\n",
    "    for name, group in grouped_data.groupby(['ewyl-group-name', 'admissions-group-name']):\n",
    "        # Keep only the last 12 attendance percentages\n",
    "        last_12_months_attendance = deque(maxlen=12)\n",
    "        for i, row in group.iterrows():\n",
    "            # Append current month's attendance to the list\n",
    "            last_12_months_attendance.append(row['attendance-percentage'])\n",
    "            \n",
    "            # If there are attendance records for at least 12 months, calculate the average\n",
    "            if len(last_12_months_attendance) == 12:\n",
    "                avg_last_12_months = sum(last_12_months_attendance) / 12\n",
    "                grouped_data.at[i, 'avg-att-percent-till-last-month'] = avg_last_12_months\n",
    "\n",
    "    return grouped_data\n",
    "\n",
    "def create_aggregate_attendance_sheet(processed_data):\n",
    "    # Convert 'date' to datetime and extract month and year\n",
    "    processed_data['date'] = pd.to_datetime(processed_data['date'])\n",
    "    processed_data['month'] = processed_data['date'].dt.strftime(\"%B\")  # Use '%B' to get the full month name\n",
    "    processed_data['year'] = processed_data['date'].dt.year\n",
    "\n",
    "    # Calculate attendance count for each group by month and year\n",
    "    attendance_count = processed_data.groupby(['ewyl-group-name', 'admissions-group-name', 'month', 'year', 'present']).size().unstack(fill_value=0)\n",
    "\n",
    "    # Calculate attendance percentage\n",
    "    total_classes = attendance_count.sum(axis=1)\n",
    "    total_present = attendance_count.get(True, 0)\n",
    "    attendance_count['attendance-percentage'] = (total_present / total_classes) * 100\n",
    "\n",
    "    # Reset index for easy manipulation\n",
    "    aggregate_data = attendance_count.reset_index()\n",
    "\n",
    "    # Calculate the average attendance percentage until the last 12 months for each group\n",
    "    for index, row in aggregate_data.iterrows():\n",
    "        group = row['ewyl-group-name']\n",
    "        year = row['year']\n",
    "        month_index = list(calendar.month_name).index(row['month'])\n",
    "\n",
    "        # Create a list to store the last 12 months' attendance percentages\n",
    "        last_12_months_attendance = []\n",
    "\n",
    "        # Loop over the last 12 months\n",
    "        for i in range(1, 13):\n",
    "            check_month_index = (month_index - i) % 12 or 12\n",
    "            check_month_name = calendar.month_name[check_month_index]\n",
    "            check_year = year if month_index - i > 0 else year - 1\n",
    "\n",
    "            # Find the matching month and year in the data\n",
    "            matching_data = aggregate_data[\n",
    "                (aggregate_data['ewyl-group-name'] == group) & \n",
    "                (aggregate_data['year'] == check_year) & \n",
    "                (aggregate_data['month'] == check_month_name)\n",
    "            ]\n",
    "\n",
    "            # Append the average attendance percentage if data is available\n",
    "            if not matching_data.empty:\n",
    "                last_12_months_attendance.append(matching_data['attendance-percentage'].values[0])\n",
    "\n",
    "        # Calculate the average of the last 12 months\n",
    "        if last_12_months_attendance:\n",
    "            avg_last_12_months = sum(last_12_months_attendance) / len(last_12_months_attendance)\n",
    "        else:\n",
    "            avg_last_12_months = 0\n",
    "\n",
    "        # Update the current row with the calculated last 12 months average attendance\n",
    "        aggregate_data.at[index, 'avg-att-percent-till-last-month'] = avg_last_12_months\n",
    "\n",
    "    # Select and rename columns to match the Bubble structure\n",
    "    aggregate_data = aggregate_data[['ewyl-group-name', 'admissions-group-name', 'attendance-percentage', 'avg-att-percent-till-last-month', 'month', 'year']]\n",
    "    aggregate_data.columns = ['ewyl-group-name', 'admissions-group-name', 'attendance-percentage', 'avg-att-percent-till-last-month', 'month', 'year']\n",
    "\n",
    "    return aggregate_data\n",
    "\n",
    "def prepare_record_for_upload(row, columns_to_include):\n",
    "    # Convert the DataFrame row to a dictionary\n",
    "    record = row.to_dict()\n",
    "\n",
    "    # Include only the desired columns\n",
    "    filtered_record = {key: value for key, value in record.items() if key in columns_to_include}\n",
    "\n",
    "    # Convert Timestamp objects to strings (ISO format)\n",
    "    for key, value in filtered_record.items():\n",
    "        if isinstance(value, pd.Timestamp):\n",
    "            filtered_record[key] = value.isoformat()\n",
    "\n",
    "    return filtered_record\n",
    "\n",
    "\n",
    "def upload_to_bubble(data, endpoint, columns_to_include):\n",
    "    headers = get_headers(endpoint)  # Get the correct headers for the endpoint\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        record = prepare_record_for_upload(row, columns_to_include)  # Pass columns_to_include to prepare_record_for_upload\n",
    "\n",
    "        try:\n",
    "            response = requests.post(endpoint, headers=headers, json=record)\n",
    "            if response.status_code == 200:\n",
    "                print(f\"Record {index} uploaded successfully\")\n",
    "            else:\n",
    "                print(f\"Error uploading record {index}: {response.text}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred while uploading record {index}: {e}\")\n",
    "\n",
    "\n",
    "def save_to_json_file(data, filepath):\n",
    "    # Convert DataFrame to a list of dictionaries\n",
    "    records = data.to_dict(orient='records')\n",
    "    # Serialize to a JSON formatted string\n",
    "    json_data = json.dumps(records, indent=4, default=str)\n",
    "    \n",
    "    # Write JSON data to file\n",
    "    with open(filepath, 'w') as file:\n",
    "        file.write(json_data)\n",
    "    print(f\"Data exported to JSON file at {filepath}\")\n",
    "\n",
    "\n",
    "# Main Function\n",
    "def main():\n",
    "    # Define your desired date range\n",
    "    start_date = '2023-01-01'\n",
    "    end_date = '2024-01-18'\n",
    "\n",
    "    # Fetch attendance and student data\n",
    "    original_data = fetch_all_attendance_data(start_date, end_date)\n",
    "    student_data = fetch_student_data()\n",
    "\n",
    "    if original_data:\n",
    "        original_df = pd.DataFrame(original_data)\n",
    "\n",
    "        # Process data with EWYL and KAM group name mapping\n",
    "        processed_data = process_and_export_data(original_df, student_data)\n",
    "\n",
    "        excel_file_path = 'C:\\\\Users\\\\ayush\\\\Documents\\\\UMS\\\\attendance_data5.xlsx'\n",
    "\n",
    "        try:\n",
    "            with pd.ExcelWriter(excel_file_path, engine='openpyxl') as writer:\n",
    "                # Export processed data to Excel\n",
    "                original_df.to_excel(writer, sheet_name='Original Data', index=False)\n",
    "                processed_data.to_excel(writer, sheet_name='Processed Data', index=False)\n",
    "            print(\"Data exported to Excel file.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        \n",
    "        # Define columns to include in JSON for processed data\n",
    "        columns_to_include_processed = ['date', 'attendance-type', 'present', 'ewyl-group-name', 'admissions-group-name']\n",
    "\n",
    "        # Create aggregate attendance data\n",
    "        aggregate_data = create_aggregate_attendance_sheet(processed_data)\n",
    "\n",
    "        # Export aggregate attendance data to Excel\n",
    "        with pd.ExcelWriter(excel_file_path, engine='openpyxl', mode='a') as writer:\n",
    "            aggregate_data.to_excel(writer, sheet_name='Aggregate Attendance', index=False)\n",
    "\n",
    "        json_file_path_processed = excel_file_path.replace('.xlsx', '_processed.json')\n",
    "        save_to_json_file(processed_data[columns_to_include_processed], json_file_path_processed)\n",
    "        \n",
    "        # Define columns to include in JSON for aggregated data\n",
    "        columns_to_include_aggregated = ['ewyl-group-name', 'admissions-group-name', 'attendance-percentage', 'avg-att-percent-till-last-month', 'month', 'year']\n",
    "        \n",
    "        json_file_path_aggregated = excel_file_path.replace('.xlsx', '_aggregated.json')\n",
    "        save_to_json_file(aggregate_data[columns_to_include_aggregated], json_file_path_aggregated)\n",
    "\n",
    "        # Define API endpoints for uploading data to Bubble\n",
    "        processed_data_upload_endpoint = UMS_API_ENDPOINT + \"/Attendance\"\n",
    "        aggregated_data_upload_endpoint = UMS_API_ENDPOINT + \"/Attendance Summary\"\n",
    "\n",
    "        # Upload Processed Data to Bubble\n",
    "        upload_to_bubble(processed_data[columns_to_include_processed], processed_data_upload_endpoint, columns_to_include_processed)\n",
    "\n",
    "        # Upload Aggregated Data to Bubble\n",
    "        upload_to_bubble(aggregate_data[columns_to_include_aggregated], aggregated_data_upload_endpoint, columns_to_include_aggregated)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
